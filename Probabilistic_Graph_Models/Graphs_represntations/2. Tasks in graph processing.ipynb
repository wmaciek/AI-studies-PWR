{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c5547c",
   "metadata": {
    "id": "e9c5547c"
   },
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946b8667",
   "metadata": {
    "id": "946b8667"
   },
   "outputs": [],
   "source": [
    "NAME = \"Maciej Wilhelmi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b0120d",
   "metadata": {
    "id": "f4b0120d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39eb517",
   "metadata": {
    "id": "d39eb517"
   },
   "source": [
    "# 2. Zadania w przetwarzaniu grafów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f0ed6",
   "metadata": {
    "id": "f39f0ed6"
   },
   "source": [
    "## 2.1. Uczenie reprezentacji wierzchołków\n",
    "\n",
    "W poniższych rozważaniach będziemy się skupiać na zadaniu uczenia reprezentacji dla wierzchołków w grafie (ang. *node embedding*). Celem będzie znalezienie funkcji $h: \\mathcal{V} \\to \\mathbb{R}^d$, która dla każdego wierzchołka $u$ wyznaczy (obliczy) jego wektor reprezentacji $\\mathbf{z}_u$. Zobaczymy, że za pomocą reprezentacji wierzchołków możemy również uzyskać reprezentacje krawędzi oraz całych grafów. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af598bd",
   "metadata": {
    "id": "4af598bd"
   },
   "source": [
    "## 2.2. Zadania uczenia maszynowego na grafach\n",
    "\n",
    "Zanim przejdziemy do omówienia konkretnych metod uczenia reprezentacji grafów, przygotujemy sobie narzędzia (funkcje) do ewaluacji otrzymanych wektorów reprezentacji trzech najpopularniejszych zadaniach związanych z przetwarzaniem grafów:\n",
    "\n",
    "1. Klasyfikacja wierzchołków\n",
    "2. Predykcja krawędzi\n",
    "3. Klasyfikacja grafów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc4ec5b",
   "metadata": {
    "id": "ffc4ec5b"
   },
   "source": [
    "## 2.3. Klasyfikacja wierzchołków\n",
    "\n",
    "Zakładamy, że każdy wierzchołek w grafie może zostać skojarzony z pewną klasą – np.:\n",
    "- w sieci społecznej – płeć,\n",
    "- w cząsteczkach chemicznych – rodzaj atomu). \n",
    "\n",
    "Korzystając z wektorów reprezentacji $\\mathbf{Z}$, uczymy klasyfikator $f$ (np. liniowy lub sieć MLP) przewidywania klasy $c_u$ danego wierzchołka $u$, tzn. $f(z_u) = c_u$ (ang. **node classification**). Musimy podzielić zbiór wierzchołków na treningowe oraz testowe. Klasyfikator uczymy na wektorach reprezentacji i klasach wierzchołków treningowych, a metryki ewaluacyjne wyliczamy uwzględniając predykcje klasyfikatora na wektorach reprezentacji wierzchołków ze zbioru testowego. \n",
    "\n",
    "Często w grafach tylko niewielka część wierzchołków jest oznaczona (ma przypisane klasy).\n",
    "\n",
    "**Uwaga:** W trakcie uczenia wektorów reprezentacji pomijamy informację o klasach wierzchołków (*unsupervised learning*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd86f30",
   "metadata": {
    "id": "fdd86f30"
   },
   "source": [
    "### Zadanie 2.1. (1.5 pkt)\n",
    "Zaimplementuj poniższą funkcję `evaluate_node_classification`, która zweryfikuje jakość podanych wektorów reprezentacji wierzchołków `z` w zadaniu klasyfikacji wierzchołków:\n",
    "\n",
    "- podziel wierzchołki grafu na zbiór treningowy oraz testowy, uwzględniając rozmiar zbioru testowego `test_size`,\n",
    "- zastosuj klasyfikator regresji logistycznej na wektorach reprezentacji oraz etykietach wierzchołków,\n",
    "- oblicz metrykę AUC na zbiorze treningowym oraz testowym.\n",
    "\n",
    "\n",
    "**Uwaga:** Pomijamy w tym zadaniu fakt, że wiele zbiorów ma zdefiniowany \"odgórnie\" podział wierzchołków - zobacz atrybuty `train_mask`, `val_mask` oraz `test_mask` w obiekcie `Data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "UtOsZadZVSPa",
   "metadata": {
    "id": "UtOsZadZVSPa"
   },
   "outputs": [],
   "source": [
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3876045e",
   "metadata": {
    "deletable": false,
    "executionInfo": {
     "elapsed": 14073,
     "status": "ok",
     "timestamp": 1684855329711,
     "user": {
      "displayName": "Maciej Wilhelmi",
      "userId": "17976457361260862912"
     },
     "user_tz": -120
    },
    "id": "3876045e",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b1f9f17d1aaa95ef7f26b9180066982",
     "grade": true,
     "grade_id": "evaluate_node_classification",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch_geometric\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate_node_classification(\n",
    "    data: Data,\n",
    "    z: torch.Tensor,\n",
    "    test_size: float = 0.4,\n",
    ") -> Dict[str, float]:\n",
    "    # TU WPISZ KOD\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    indices = torch.arange(num_nodes)\n",
    "\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        indices, test_size=test_size, random_state=42\n",
    "    )\n",
    "\n",
    "    # nasze dane\n",
    "    z_train = z[train_indices]\n",
    "    z_test = z[test_indices]\n",
    "    # nasze etykiety\n",
    "    y_train = data.y[train_indices]\n",
    "    y_test = data.y[test_indices]\n",
    "\n",
    "    # regresja logistyczna\n",
    "    model = LogisticRegression().fit(z_train, y_train)\n",
    "    \n",
    "    preds_train = model.predict_proba(z_train)\n",
    "    preds_test = model.predict_proba(z_test)\n",
    "\n",
    "    auc_train = roc_auc_score(y_train, preds_train, multi_class='ovr')\n",
    "    auc_test = roc_auc_score(y_test, preds_test, multi_class='ovr')\n",
    "\n",
    "    results = {\n",
    "        \"train_auc\": auc_train,\n",
    "        \"test_auc\": auc_test,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1426339",
   "metadata": {
    "id": "a1426339"
   },
   "source": [
    "Zweryfikujmy, że funkcja działa na losowo zainicjalizowanej macierzy wektorów reprezentacji wierzchołków i zbiorze Cora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab6ca4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1679,
     "status": "ok",
     "timestamp": 1684855331374,
     "user": {
      "displayName": "Maciej Wilhelmi",
      "userId": "17976457361260862912"
     },
     "user_tz": -120
    },
    "id": "9ab6ca4f",
    "outputId": "5b4eed85-c7f6-4269-9088-1f7e1e037712"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_auc': 0.7447835710684279, 'test_auc': 0.5119679007496767}\n"
     ]
    }
   ],
   "source": [
    "def test_evaluate_node_classification():\n",
    "    from torch_geometric.datasets import Planetoid\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    data = Planetoid(root=\"./data/\", name=\"Cora\")[0]\n",
    "    z = torch.randn(data.num_nodes, 128)\n",
    "\n",
    "    metrics = evaluate_node_classification(data=data, z=z)\n",
    "\n",
    "    assert \"train_auc\" in metrics\n",
    "    assert \"test_auc\" in  metrics\n",
    "\n",
    "    print(metrics)\n",
    "    \n",
    "    \n",
    "test_evaluate_node_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b895ff9",
   "metadata": {
    "id": "8b895ff9"
   },
   "source": [
    "## 2.4. Predykcja krawędzi\n",
    "\n",
    "W wielu przypadkach możemy założyć, że nie posiadamy pełnej informacji o strukturze grafu, tzn. nie obserwujemy w zbiorze wszystkich krawędzi, które w rzeczywistości istnieją w danym grafie. Możemy jednak wyuczyć model, który uzupełni brakujące krawędzie (ang. **link prediction**). \n",
    "\n",
    "Zbiór krawędzi grafu dzielimy na zbiór treningowy oraz testowy. Krawędzie ze zbioru testowego *usuwamy z grafu*, aby były nieobserwowane w trakcie uczenia wektorów reprezentacji. W niektórych wariantach tego zadania, staramy się również podzielić wierzchołki tak, aby krawędzie testowe występowały tylko między wybranym podzbiorem wierzchołków (które również na czas uczenia usuwamy) – ten scenariusz jednak nie będziemy stosować w ramach zajęć.\n",
    "\n",
    "Na tym etapie możemy zauważyć pewnien problem – mamy tylko informację o istniejących w grafie krawędziach. Nie wiadomo jak wyuczyć model klasyfikatora? Potrzebowalibyśmy jeszcze informacji o krawędziach, które nie istnieją w grafie, wtedy możemy uznać istniejące krawędzie (przykłady pozytywne) jako klasę $1$, a nieistniejące (przykłady negatywne) jako klasę $0$. \n",
    "\n",
    "Dokładnie tak rozwiążemy nasz problem – każdej krawędzi w obecnym zbiorze treningowym i testowym przypisujemy klasę $1$. Następnie dla każdej krawędzi losujemy ze zbioru wszystkich możliwych krawędzi, taką która nie istnieje w danym grafie i przypisujemy jej klasę $0$ (ang. *balanced negative sampling*).\n",
    "\n",
    "Wybór odpowiednich negatywnych przypadków jest bardziej skomplikowany i istnieje wiele strategii losowania, jednak pozostaniemy przy najprostszym scenariuszu losując krawędź zgodnie z rozkładem jednostajnym (tzn. każdy wybór tak samo prawdopodobny).\n",
    "\n",
    "Kolejnym zagadnieniem jest jak otrzymać wektor reprezentacji dla krawędzi, skoro założyliśmy, że korzystamy z wektorów dla wierzchołków? Tutaj również mamy wiele możliwości, jednak najpopularniejszym rozwiązaniem jest wykorzystanie jednej z następujących transformacji wektorów reprezentacji wierzchołków $z_{uv} = z_u \\circ z_v$, gdzie $\\circ: \\mathcal{V} \\times \\mathcal{V} \\to \\mathbb{R}^{d}$. Metody te zostały zaproponowane w pracy [Node2vec](https://arxiv.org/pdf/1607.00653.pdf) i są aplikowane na każdym elemencie wektora reprezentacji osobno (ang. *element-wise*):\n",
    "\n",
    "| Nazwa | Wzór  |\n",
    "|-------|-------|\n",
    "| Średnia  | $$ z_{uv} = \\frac{z_u + z_v}{2}$$ |\n",
    "| Hadamard | $$ z_{uv} = z_u * z_v$$ |\n",
    "| L1       | $$ z_{uv} = |z_u - z_v|$$ |\n",
    "| L2       | $$ z_{uv} = |z_u - z_v|^2$$ |\n",
    "\n",
    "Po przekształceniu wektorów reprezentacji wierzchołków na wektory krawędzi, możemy wyuczyć klasyfikator binarny na wektorach krawędzi ze zbioru treningowego (uwzględniając przypadki pozytywne i negatywne), a następnie wyliczyć wartości miar ewaluacyjnych w oparciu o predykcje klasyfikatora na wektorach krawędzi ze zbioru testowego."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8d3351",
   "metadata": {
    "id": "ed8d3351"
   },
   "source": [
    "### Zadanie 2.2 (5 pkt)\n",
    "Zaimplementuj następujące funkcje:\n",
    "\n",
    "- `prepare_train_test_sets` (2 pkt):\n",
    "    - podaną listę krawędzi `edge_index` podziel na zbiór treningowy (`train_edges_pos`) oraz testowy (`test_edges_pos`) uwzględniając wielkość zbioru testowego `test_size`,\n",
    "    - dla każdej krawędzi wylosuj przypadek negatywny: `train_edges_neg` oraz `test_edges_neg` (zobacz funkcję `negative_sampling` z biblioteki PyTorch-Geometric),\n",
    "    - utwórz listę (tensor) krawędzi treningowych `train_edges` (konkatenacja `train_edges_pos` oraz `train_edges_neg`) o wymiarach `2 x łączna liczba krawędzi`,\n",
    "    - utwórz taką samą listę dla krawędzi testowych `test_edges`,\n",
    "    - utwórz wektory etykiet (zera i jedynki): `y_train` oraz `y_test`.\n",
    "    \n",
    "- `transform_to_edge_embeddings` (2 pkt):\n",
    "    - dla podanej listy krawędzi `edge_index` oraz wektorów reprezentacji wierzchołków `z` obliczy reprezentacje krawędzi\n",
    "    - argument `transformation_name` wyznacza metodę transformacji: \"average\", \"hadamard\", \"L1\" lub \"L2\" (zgodnie z powyższą tabelką)\n",
    "\n",
    "- `evalute_link_prediction` (1 pkt):\n",
    "    - dla podanych: listy krawędzi treningowych `train_edges` (wraz z `y_train`) oraz testowych `test_edges` (wraz z `y_test`), metody transformacji do reprezentacji krawędzi `transformation_name` oraz reprezentacji wierzchołków `z`, przeprowadzi ewaluację tych reprezentacji w zadaniu predykcji krawędzi\n",
    "    - zastosuj klasyfikator regresji logistycznej\n",
    "    - oblicz miary AUC dla zbioru treningowego i testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ec9dc9",
   "metadata": {
    "deletable": false,
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1684855340813,
     "user": {
      "displayName": "Maciej Wilhelmi",
      "userId": "17976457361260862912"
     },
     "user_tz": -120
    },
    "id": "e0ec9dc9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8da3c78f9c1895c28b6233573584c61f",
     "grade": true,
     "grade_id": "prepare_train_test_sets",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "\n",
    "def prepare_train_test_sets(\n",
    "    edge_index: torch.Tensor,\n",
    "    test_size: float = 0.4,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    # TU WPISZ KOD\n",
    "    train_edges_pos, test_edges_pos = train_test_split(\n",
    "        edge_index.T, test_size=test_size, random_state=42\n",
    "    )\n",
    "\n",
    "    train_edges_pos = train_edges_pos.T  #powrót do wymiarów sprzed splitu\n",
    "    test_edges_pos = test_edges_pos.T\n",
    "\n",
    "    all_nodes_len = len(torch.cat([edge_index[0], edge_index[1]]).unique())\n",
    "\n",
    "    train_edges_neg = negative_sampling(\n",
    "        edge_index=train_edges_pos, num_nodes=all_nodes_len\n",
    "    )\n",
    "\n",
    "    test_edges_neg = negative_sampling(\n",
    "        edge_index=test_edges_pos, num_nodes=all_nodes_len\n",
    "    )\n",
    "\n",
    "    train_edges = torch.cat([train_edges_pos, train_edges_neg], dim=1)\n",
    "    test_edges = torch.cat([test_edges_pos, test_edges_neg], dim=1)\n",
    "\n",
    "    y_train = torch.cat(\n",
    "        [torch.ones(train_edges_pos[1].shape),\n",
    "         torch.zeros(train_edges_pos[1].shape)]\n",
    "         )\n",
    "        \n",
    "    y_test = torch.cat(\n",
    "        [torch.ones(test_edges_pos[1].shape),\n",
    "         torch.zeros(test_edges_pos[1].shape)]\n",
    "         )\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"train_edges_pos\": train_edges_pos,\n",
    "        \n",
    "        \"train_edges\": train_edges,\n",
    "        \"y_train\": y_train,\n",
    "        \n",
    "        \"test_edges\": test_edges,\n",
    "        \"y_test\": y_test,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "def test_prepare_train_test_sets():\n",
    "    from torch_geometric.datasets import Planetoid\n",
    "    \n",
    "    data = Planetoid(root=\"./data/\", name=\"Cora\")[0]\n",
    "\n",
    "    train_size = 0.6\n",
    "    out = prepare_train_test_sets(\n",
    "        edge_index=data.edge_index,\n",
    "        test_size=1 - train_size,\n",
    "    )\n",
    "\n",
    "    num_train_edges_pos = int(train_size * data.num_edges)\n",
    "    num_test_edges_pos = data.num_edges - num_train_edges_pos\n",
    "    \n",
    "    assert out[\"train_edges_pos\"].shape[1] == num_train_edges_pos\n",
    "    \n",
    "    assert out[\"train_edges\"].shape == (2, 2 * num_train_edges_pos)\n",
    "    assert out[\"y_train\"].shape == (2 * num_train_edges_pos,)\n",
    "    \n",
    "    assert out[\"test_edges\"].shape == (2, 2 * num_test_edges_pos)\n",
    "    assert out[\"y_test\"].shape == (2 * num_test_edges_pos,)\n",
    "    \n",
    "    \n",
    "test_prepare_train_test_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed8fa2ce",
   "metadata": {
    "deletable": false,
    "executionInfo": {
     "elapsed": 7790,
     "status": "ok",
     "timestamp": 1684855360486,
     "user": {
      "displayName": "Maciej Wilhelmi",
      "userId": "17976457361260862912"
     },
     "user_tz": -120
    },
    "id": "ed8fa2ce",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b70b36b888d03164b52d810dd8c57778",
     "grade": true,
     "grade_id": "transform_to_edge_embeddings",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transform_to_edge_embeddings(\n",
    "    edge_index: torch.Tensor,\n",
    "    z: torch.Tensor,\n",
    "    transformation_name: str,\n",
    ") -> torch.Tensor:\n",
    "    # TU WPISZ KOD\n",
    "    if transformation_name=='average':\n",
    "      return (z[edge_index[0]] + z[edge_index[1]]) / 2\n",
    "    elif transformation_name=='hadamard':\n",
    "      return (z[edge_index[0]] * z[edge_index[1]])\n",
    "    elif transformation_name=='L1':\n",
    "      return torch.abs(z[edge_index[0]] - z[edge_index[1]])\n",
    "    else:\n",
    "      return torch.abs(z[edge_index[0]] - z[edge_index[1]])**2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_transform_to_edge_embeddings():\n",
    "    ei = torch.tensor([[0], [1]])\n",
    "    z = torch.tensor([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "    ])\n",
    "    \n",
    "    assert (transform_to_edge_embeddings(ei, z, \"average\") == torch.tensor([[2.5, 3.5, 4.5]])).all()\n",
    "    assert (transform_to_edge_embeddings(ei, z, \"hadamard\") == torch.tensor([[4, 10, 18]])).all()\n",
    "    assert (transform_to_edge_embeddings(ei, z, \"L1\") == torch.tensor([[3, 3, 3]])).all()\n",
    "    assert (transform_to_edge_embeddings(ei, z, \"L2\") == torch.tensor([[9, 9, 9]])).all()\n",
    "    \n",
    "    \n",
    "test_transform_to_edge_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qK4jFAhXtG-F",
   "metadata": {
    "id": "qK4jFAhXtG-F"
   },
   "source": [
    "evalute_link_prediction (1 pkt):\n",
    "\n",
    "dla podanych: listy krawędzi treningowych train_edges (wraz z y_train) oraz testowych test_edges (wraz z y_test), metody transformacji do reprezentacji krawędzi transformation_name oraz reprezentacji wierzchołków z, przeprowadzi ewaluację tych reprezentacji w zadaniu predykcji krawędzi\n",
    "zastosuj klasyfikator regresji logistycznej\n",
    "oblicz miary AUC dla zbioru treningowego i testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14891030",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684855364557,
     "user": {
      "displayName": "Maciej Wilhelmi",
      "userId": "17976457361260862912"
     },
     "user_tz": -120
    },
    "id": "14891030",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f523b30f7c3ad14b2cdc57c967dc914",
     "grade": true,
     "grade_id": "evaluate_link_prediction",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "730a0864-02fd-40ce-9bcc-729ce0a40d56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_auc': 0.5698720985315016, 'test_auc': 0.5488988870471229}\n"
     ]
    }
   ],
   "source": [
    "def evaluate_link_prediction(\n",
    "    train_edges: torch.Tensor,\n",
    "    y_train: torch.Tensor,\n",
    "    test_edges: torch.Tensor,\n",
    "    y_test: torch.Tensor,\n",
    "    transformation_name: str,\n",
    "    z: torch.Tensor,\n",
    ") -> Dict[str, float]:\n",
    "    # TU WPISZ KOD\n",
    "    z_train = transform_to_edge_embeddings(train_edges, z, transformation_name)\n",
    "\n",
    "    z_test = transform_to_edge_embeddings(test_edges, z, transformation_name)\n",
    "\n",
    "    \n",
    "    # regresja logistyczna\n",
    "    model = LogisticRegression().fit(z_train, y_train)\n",
    "    \n",
    "    preds_train = model.predict(z_train)\n",
    "    preds_test = model.predict(z_test)\n",
    "\n",
    "\n",
    "    auc_train = roc_auc_score(y_train, preds_train, multi_class='ovr')\n",
    "    auc_test = roc_auc_score(y_test, preds_test, multi_class='ovr')\n",
    "\n",
    "    results = {\n",
    "        \"train_auc\": auc_train,\n",
    "        \"test_auc\": auc_test,\n",
    "    }\n",
    "\n",
    "    return results\n",
    "    \n",
    "\n",
    "def test_evaluate_link_prediction():\n",
    "    from torch_geometric.datasets import Planetoid\n",
    "    \n",
    "    data = Planetoid(root=\"./data/\", name=\"Cora\")[0]\n",
    "\n",
    "    out = prepare_train_test_sets(edge_index=data.edge_index)\n",
    "    \n",
    "    z = torch.randn(data.num_nodes, 128)\n",
    "    \n",
    "    metrics = evaluate_link_prediction(\n",
    "        train_edges=out[\"train_edges\"],\n",
    "        y_train=out[\"y_train\"],\n",
    "        test_edges=out[\"test_edges\"],\n",
    "        y_test=out[\"y_test\"],\n",
    "        transformation_name=\"average\",\n",
    "        z=z,\n",
    "    )\n",
    "    \n",
    "    assert \"train_auc\" in metrics.keys()\n",
    "    assert \"test_auc\" in metrics.keys()\n",
    "    \n",
    "    print(metrics)\n",
    "\n",
    "\n",
    "test_evaluate_link_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f64dc6",
   "metadata": {
    "id": "e3f64dc6"
   },
   "source": [
    "## 2.5. Klasyfikacja grafów\n",
    "\n",
    "Zadanie to jest podobne do klasyfikacji wierzchołków, przy czym tutaj klasa jest przypisana do całego grafu. Przykładem może być klasyfikacja białek (reprezentowanych jako grafy). \n",
    "\n",
    "Podejście jest analogiczne jak w punkcie **2.3**. Zbiór grafów dzielimy na zbiór treningowy oraz testowy i uczymy odpowiedni klasyfikator. Jedynym zagadnieniem, które musimy rozwiązać jest sposób uzyskania wektora reprezentacji dla całego grafu na podstawie wektorów reprezentacji pojedynczych wierzchołków. Będziemy rozważać proste przekształcenia, które będą agregować wektory wierzchołków w jeden wektor opisujacy cały graf:\n",
    "\n",
    "- uśrednianie: $z_\\mathcal{G} = \\frac{1}{|\\mathcal{V}|} \\sum_{u \\in \\mathcal{V}} z_u$\n",
    "- redukcja max (ang. **max pooling**): $z_\\mathcal{G} = \\max_i \\{z_1^{(i)}, z_2^{(i)}, \\ldots, z_{|\\mathcal{V}|}^{(i)} \\} \\;\\forall i = 1 \\ldots d$, gdzie $z_u^{(i)}$ oznacza $i$-ty element wektora $z_u$,\n",
    "- redukcja min (ang. **min pooling**): $z_\\mathcal{G} = \\min_i \\{z_1^{(i)}, z_2^{(i)}, \\ldots, z_{|\\mathcal{V}|}^{(i)} \\} \\;\\forall i = 1 \\ldots d$\n",
    "\n",
    "Możemy również zastosować inne strategie wyznaczania wektora opisującego cały graf, ale więcej o tym na następnym wykładzie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caa8c81",
   "metadata": {
    "id": "6caa8c81"
   },
   "source": [
    "### Zadanie 2.3. (3.5 pkt)\n",
    "Zaimplementuj funkcje:\n",
    "\n",
    "- `transform_to_graph_embedding` (1.5 pkt):\n",
    "    - dla podanej macierzy reprezentacji wierzchołków `z` wyznaczy wektor reprezentacji całego grafu\n",
    "    - argument `transformation_name` wyznacza metodę transformacji: \"average\", \"max_pooling\", \"min_pooling\"\n",
    "    \n",
    "- `evaluate_graph_classification` (2 pkt):\n",
    "    - dla podanej listy macierzy reprezentacji grafów `z`, wektora etykiet grafów `y` oraz metody transformacji `transformation_name`, przeprowadzi ewaluację reprezentacji w zadaniu klasyfikacji grafów\n",
    "    - podziel grafy na zbiór treningowy oraz testowy, gdzie wielkość zbioru testowego jest określona za pomocą parametru `test_size`,\n",
    "    - przetransformuj listę macierzy reprezentacji wierzchołków w jedną macierz reprezentacji grafów,\n",
    "    - zastosuj klasyfikator regresji logistycznej\n",
    "    - oblicz miary AUC dla zbioru treningowego i testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cpMHWtqN0Z7D",
   "metadata": {
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1684855433366,
     "user": {
      "displayName": "Maciej Wilhelmi",
      "userId": "17976457361260862912"
     },
     "user_tz": -120
    },
    "id": "cpMHWtqN0Z7D"
   },
   "outputs": [],
   "source": [
    "def transform_to_graph_embedding(\n",
    "    z: torch.Tensor,\n",
    "    transformation_name: str,\n",
    ") -> torch.Tensor:\n",
    "    # TU WPISZ KOD\n",
    "    if transformation_name=='average':\n",
    "      return z.sum(dim=0)/z.shape[0]\n",
    "    if transformation_name=='max_pooling':\n",
    "      return z.max(dim=0).values\n",
    "    if transformation_name=='min_pooling':\n",
    "      return z.min(dim=0).values\n",
    "  \n",
    "\n",
    "def test_transform_to_graph_embedding():\n",
    "    z = torch.tensor([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9],\n",
    "    ])\n",
    "    \n",
    "    assert (transform_to_graph_embedding(z, \"average\") == torch.tensor([4, 5, 6])).all()\n",
    "    assert (transform_to_graph_embedding(z, \"max_pooling\") == torch.tensor([7, 8, 9])).all()\n",
    "    assert (transform_to_graph_embedding(z, \"min_pooling\") == torch.tensor([1, 2, 3])).all()\n",
    "\n",
    "test_transform_to_graph_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd10ab3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1684857829447,
     "user": {
      "displayName": "Maciej Wilhelmi",
      "userId": "17976457361260862912"
     },
     "user_tz": -120
    },
    "id": "fd10ab3a",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae4567ab06aed96be0a4cd47e134bb79",
     "grade": true,
     "grade_id": "evaluate_graph_classification",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "dacaffad-310c-4fd2-c224-b62fc5032341"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_graph_classification\u001b[39m(\n\u001b[0;32m----> 5\u001b[0m     z: List[\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m      6\u001b[0m     y: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m      7\u001b[0m     transformation_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m      8\u001b[0m     test_size: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.4\u001b[39m,\n\u001b[1;32m      9\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# TU WPISZ KOD\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     z_train, z_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     13\u001b[0m         z, y, test_size\u001b[38;5;241m=\u001b[39mtest_size, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     16\u001b[0m     z_x \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def evaluate_graph_classification(\n",
    "    z: List[torch.Tensor],\n",
    "    y: torch.Tensor,\n",
    "    transformation_name: str,\n",
    "    test_size: float = 0.4,\n",
    ") -> Dict[str, float]:\n",
    "    # TU WPISZ KOD\n",
    "\n",
    "    z_train, z_test, y_train, y_test = train_test_split(\n",
    "        z, y, test_size=test_size, random_state=42\n",
    "    )\n",
    "\n",
    "    z_x = []\n",
    "    for z in z_train:\n",
    "      z_x.append(transform_to_graph_embedding(z, transformation_name))\n",
    "\n",
    "    z_y = []\n",
    "    for z in z_test:\n",
    "      z_y.append(transform_to_graph_embedding(z, transformation_name))\n",
    "\n",
    "\n",
    "    z_train = torch.stack(z_x)\n",
    "    z_test = torch.stack(z_y)\n",
    "\n",
    "    \n",
    "    # regresja logistyczna\n",
    "    model = LogisticRegression(max_iter=500).fit(z_train, y_train)\n",
    "    preds_train = model.predict_proba(z_train)\n",
    "    preds_test = model.predict_proba(z_test)\n",
    "\n",
    "\n",
    "    auc_train = roc_auc_score(y_train, preds_train, multi_class='ovr')\n",
    "    auc_test = roc_auc_score(y_test, preds_test, multi_class='ovr')\n",
    "\n",
    "    results = {\n",
    "        \"train_auc\": auc_train,\n",
    "        \"test_auc\": auc_test,\n",
    "    }\n",
    "\n",
    "    return results\n",
    "    \n",
    "    \n",
    "    \n",
    "def test_evaluate_graph_classification():\n",
    "    from torch_geometric.datasets import TUDataset\n",
    "    \n",
    "    enzymes = TUDataset(root=\"./data\", name=\"ENZYMES\")\n",
    "    \n",
    "    y = torch.tensor([e.y for e in enzymes])\n",
    "    z = [torch.randn(e.num_nodes, 128) for e in enzymes]\n",
    "\n",
    "    metrics = evaluate_graph_classification(z, y, \"average\")\n",
    "    \n",
    "    assert \"train_auc\" in metrics.keys()\n",
    "    assert \"test_auc\" in metrics.keys()\n",
    "    \n",
    "    print(metrics)\n",
    "    \n",
    "    \n",
    "test_evaluate_graph_classification()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
